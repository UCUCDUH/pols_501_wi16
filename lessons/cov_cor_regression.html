<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Andreu Casas" />

<meta name="date" content="2016-02-26" />

<title>Lab 8: Covariance, Correlation, and Regression</title>

<script src="libs/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.1/css/cerulean.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.1/shim/respond.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="libs/highlight/textmate.css"
      type="text/css" />
<script src="libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">

<p>
<strong>POL S/CS&amp;SS 501, University of Washington, Winter 2016</strong>
</p>

$$
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\SE}{se}
\DeclareMathOperator{\SD}{sd}
\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\argmax}{argmax}
$$

<div id="header">
<h1 class="title">Lab 8: Covariance, Correlation, and Regression</h1>
<h4 class="author"><em>Andreu Casas</em></h4>
<h4 class="date"><em>February 26, 2016</em></h4>
</div>


<div id="outline" class="section level3">
<h3>Outline</h3>
<p>In this lab we’ll look at different methdos to study the relationship between variables.</p>
<ol style="list-style-type: decimal">
<li>Covariance</li>
<li>Correlation</li>
<li>Regression</li>
</ol>
</div>
<div id="intro" class="section level3">
<h3>Intro</h3>
<p>We’ll use the dataset <code>Prestige</code> from the package <code>car</code>. Install it if you don’t have it. We will also use other packages that we’ve already used in previous labs: <code>dplyr</code>, <code>ggplot2</code>, <code>broom</code>.</p>
<pre class="r"><code>library(car)
library(dplyr)
library(tidyr)
library(ggplot2)
library(broom)
library(GGally)</code></pre>
<p>Load the dataset <code>Presige</code> in the package <code>car</code> and take a look at it.</p>
<pre class="r"><code>data(&quot;Prestige&quot;)
glimpse(Prestige)</code></pre>
<pre><code>## Observations: 102
## Variables: 6
## $ education (dbl) 13.11, 12.26, 12.77, 11.42, 14.62, 15.64, 15.09, 15....
## $ income    (int) 12351, 25879, 9271, 8865, 8403, 11030, 8258, 14163, ...
## $ women     (dbl) 11.16, 4.02, 15.70, 9.11, 11.68, 5.13, 25.65, 2.69, ...
## $ prestige  (dbl) 68.8, 69.1, 63.4, 56.8, 73.5, 77.6, 72.6, 78.1, 73.1...
## $ census    (int) 1113, 1130, 1171, 1175, 2111, 2113, 2133, 2141, 2143...
## $ type      (fctr) prof, prof, prof, prof, prof, prof, prof, prof, pro...</code></pre>
<p>The dataset was constructed using 1971 census data from Canada. Each observation of the dataset (nrow = 102) is an occupation (e.g. biologists, secretaries, athletes, etc.) and the variables are: the average <code>education</code> and <code>income</code> for the respondents with those occupations, the percentage of <code>women</code> respondents, the <code>prestige</code> of the occupation (Pineo-Porter prestige score: social survey from the 1960s), and <code>type</code>of occupation (Blue collar -bc-, Professional -prof-, and White Collar -wc-).</p>
</div>
<div id="covariance" class="section level3">
<h3>Covariance</h3>
<p>Imagine that we were interested in studying if there is a relationship between the average level of <code>education</code> for respondents with any given occupation and the average <code>income</code>.</p>
<p>One way to study such relationship would be to look at the <code>covariance</code>. Let’s start by to calculating the covariance between these 2 variables“manually” we need to know: the values of the two variables (<code>y</code>, <code>x</code>), their means (<code>yhat</code>, <code>xhat</code>), and the sample size (<code>n</code>).</p>
<pre class="r"><code>x &lt;- Prestige$education
y &lt;- Prestige$income
n &lt;- nrow(Prestige)
xhat &lt;- mean(Prestige$education)
yhat &lt;- mean(Prestige$income)
covariance &lt;- sum((y - mean(y)) * (x - mean(x))) / (n-1)
covariance</code></pre>
<pre><code>## [1] 6691.13</code></pre>
<p>In <code>R</code> we can also calculate the covariance using the function <code>cov()</code>. This function takes two vectors of the same length and calculates the covariance.</p>
<pre class="r"><code>cov(Prestige$education, Prestige$income)</code></pre>
<pre><code>## [1] 6691.13</code></pre>
</div>
<div id="correlation" class="section level3">
<h3>Correlation</h3>
<p>One of the analytical downsides of calculating the covariance to study the relationship between two variables is that the resulting estimator is scale-dependent and it’s hard to compare it to other covariance estimators. To address this issue, we often calculate intsead the <code>correlation</code> of two variables; which is a standardized statistic that ranges from -1 to 1. Positive correlation values indicate a positive relationship and negative values a negative one. The closer the statistic is to -1 or to 1, the stronger the relationship between these two variables.</p>
<p>Let’s do the same we did with the covariance and calculate first the correlation between <code>education</code> and <code>income</code> manually. To do so we need: the covariance of x and y (<code>covariance</code>), the variance of x (<code>varx</code>) and the variance of y (<code>vary</code>)</p>
<pre class="r"><code>sx &lt;- sd(Prestige$education)
sy &lt;- sd(Prestige$income)
cor_xy &lt;- covariance / (sx * sy)
cor_xy</code></pre>
<pre><code>## [1] 0.5775802</code></pre>
<p>As it happened with calculating the covariance, there is also an <code>R</code> function to calculate the correlation of two variables: <code>cor()</code>. This variable also takes two vectors of the same length.</p>
<pre class="r"><code>cor(Prestige$income, Prestige$education)</code></pre>
<pre><code>## [1] 0.5775802</code></pre>
<div id="challenge-1" class="panel panel-primary">
<div class="panel-heading">
<h3 class="panel-title">
Challenge
</h3>
</div>
<div class="panel-body">
<p>What other varibales of the <code>Prestige</code> dataset do you think are strongly related? Calculate the variance and the correlation between 2 other variables</p>
</div>
</div>
<p>You can also use <code>R</code> to calculate the correlation between all numeric variables in a dataset; but they have to be numerical! (<code>numeric</code> and <code>integer</code> <code>R</code> variables). To do that, let’s create a subset of Prestige only with the numeric variables <code>education</code>, <code>income</code>, <code>women</code>, and <code>prestige</code>.</p>
<pre class="r"><code>prestige_num &lt;- select(Prestige, education, income, women, prestige)
prestige_cor &lt;- round(cor(prestige_num), 2)
prestige_cor</code></pre>
<pre><code>##           education income women prestige
## education      1.00   0.58  0.06     0.85
## income         0.58   1.00 -0.44     0.71
## women          0.06  -0.44  1.00    -0.12
## prestige       0.85   0.71 -0.12     1.00</code></pre>
<p>Instead of having a table with the correlation between all numeric variables, we can also create a plot.</p>
<div id="challenge-2" class="panel panel-primary">
<div class="panel-heading">
<h3 class="panel-title">
Challenge
</h3>
</div>
<div class="panel-body">
<p>To create a correlation plot we need <code>pretige_cor</code> to be a tidy dataset. Try to arrange the dataset so that we have a dataset with three variables (<code>var1</code>,<code>var2</code>,<code>value</code>), where each observation is a pair of two variables and the correlation between them.</p>
</div>
</div>
<p>We first need to organize the dataset so that we can then plot the data using <code>geom_tile()</code> from <code>ggplot2</code>.</p>
<pre class="r"><code>prestige_cor_new &lt;- as.data.frame(prestige_cor) %&gt;%
  gather(var1, value) %&gt;%
  mutate(var2 = rep(unique(var1), nrow(prestige_cor)))</code></pre>
<p>And now we plot the correlation between the variables in <code>Prestige</code>:</p>
<pre class="r"><code>ggplot(prestige_cor_new, aes(var1, var2))+
 geom_tile(data=prestige_cor_new, aes(fill=value), color=&quot;white&quot;)+
 scale_fill_gradient2(low=&quot;blue&quot;, high=&quot;red&quot;, mid=&quot;white&quot;, 
  midpoint=0, limit=c(-1,1), name=&quot;Correlation\n(Pearson)&quot;)+
 theme(axis.text.x = element_text(angle=45, vjust=1, size=11, hjust=1))+
 coord_equal() + labs(x = &quot;&quot;, y = &quot;&quot;) +
  ggtitle(&quot;Correlation Plot&quot;)</code></pre>
<p><img src="cov_cor_regression_files/figure-html/unnamed-chunk-9-1.png" title="" alt="" width="672" /></p>
<p>Another function that allows us to visually look at the correlation between variables in our dataset is the <code>ggpairs()</code> function of the <code>GGally</code> package. This function plots: - distribution of each variable - relationship of between each pair of variables - reports Pearson correlation coeficients for all pairs</p>
<pre class="r"><code>ggpairs(prestige_num)</code></pre>
<p><img src="cov_cor_regression_files/figure-html/unnamed-chunk-10-1.png" title="" alt="" width="672" /></p>
</div>
<div id="regression" class="section level3">
<h3>Regression</h3>
<p>The basic <code>R</code> command for linear regression is <code>lm()</code>. We need to specify two main arguments in this function: the name of the dataset containing the key variables (<code>data =</code>) and the formula expressing our model (<code>formula =</code>). For the <code>formula</code> argument, we use the symbol <code>~</code> to separate the right from the left side of the equation.</p>
<pre class="r"><code>reg &lt;- lm(data = Prestige, formula = prestige ~ income)</code></pre>
<p>There are multiple ways to look at and explore the output of the regression:</p>
<ol style="list-style-type: decimal">
<li>If we just type the resulting object in the console, <code>reg</code> in our case, <code>R</code> returns the formula of the model that generated that output + the coefficients for each covariate and the intercept. Not much info.</li>
</ol>
<pre class="r"><code>reg</code></pre>
<pre><code>## 
## Call:
## lm(formula = prestige ~ income, data = Prestige)
## 
## Coefficients:
## (Intercept)       income  
##   27.141176     0.002897</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>We can also use the <code>summary()</code> function and insert the regression output (<code>reg</code>) as argument to get further details. In particular <code>R</code> returns:</li>
</ol>
<ul>
<li>Formula of the model</li>
<li>Summary of the residuals</li>
<li>A table with the:
<ul>
<li>Coefficients</li>
<li>SEs</li>
<li>T-Values</li>
<li>P-Values</li>
</ul></li>
<li>Multiple R-squared info</li>
<li>F-statistic</li>
</ul>
<pre class="r"><code>summary(reg)</code></pre>
<pre><code>## 
## Call:
## lm(formula = prestige ~ income, data = Prestige)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -33.007  -8.378  -2.378   8.432  32.084 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2.714e+01  2.268e+00   11.97   &lt;2e-16 ***
## income      2.897e-03  2.833e-04   10.22   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 12.09 on 100 degrees of freedom
## Multiple R-squared:  0.5111, Adjusted R-squared:  0.5062 
## F-statistic: 104.5 on 1 and 100 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>The regression output <code>reg</code> contains more information than the one that the <code>summary()</code> function returns. To take a look at the different info in <code>reg</code>, use the <code>str()</code> function. You can do the same with the output of a large number of statistical tests in <code>R</code>. You can pull out any of these elements within the regression output object using the <code>$</code> dolar sign. Or you can also use the dolar sign to pull out an object from the <code>summary</code> of <code>reg</code> (<code>summary(reg)</code>). For example, you could pull out:</li>
</ol>
<ul>
<li><code>$coefficients</code>: the coefficients for all the variables.</li>
<li><code>$fitted.values</code>: the predictions made by the model using the estimated coefficients</li>
<li><code>$residuals</code>: the difference betweent the predicted and actual values</li>
<li>…</li>
</ul>
<pre class="r"><code>str(reg)</code></pre>
<pre><code>## List of 12
##  $ coefficients : Named num [1:2] 27.1412 0.0029
##   ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;income&quot;
##  $ residuals    : Named num [1:102] 5.88 -33.01 9.4 3.98 22.02 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:102] &quot;gov.administrators&quot; &quot;general.managers&quot; &quot;accountants&quot; &quot;purchasing.officers&quot; ...
##  $ effects      : Named num [1:102] -472.99 -123.61 9.95 4.31 22.09 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:102] &quot;(Intercept)&quot; &quot;income&quot; &quot;&quot; &quot;&quot; ...
##  $ rank         : int 2
##  $ fitted.values: Named num [1:102] 62.9 102.1 54 52.8 51.5 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:102] &quot;gov.administrators&quot; &quot;general.managers&quot; &quot;accountants&quot; &quot;purchasing.officers&quot; ...
##  $ assign       : int [1:2] 0 1
##  $ qr           :List of 5
##   ..$ qr   : num [1:102, 1:2] -10.1 0.099 0.099 0.099 0.099 ...
##   .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. ..$ : chr [1:102] &quot;gov.administrators&quot; &quot;general.managers&quot; &quot;accountants&quot; &quot;purchasing.officers&quot; ...
##   .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;income&quot;
##   .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1
##   ..$ qraux: num [1:2] 1.1 1.44
##   ..$ pivot: int [1:2] 1 2
##   ..$ tol  : num 1e-07
##   ..$ rank : int 2
##   ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot;
##  $ df.residual  : int 100
##  $ xlevels      : Named list()
##  $ call         : language lm(formula = prestige ~ income, data = Prestige)
##  $ terms        :Classes &#39;terms&#39;, &#39;formula&#39; length 3 prestige ~ income
##   .. ..- attr(*, &quot;variables&quot;)= language list(prestige, income)
##   .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1
##   .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. .. ..$ : chr [1:2] &quot;prestige&quot; &quot;income&quot;
##   .. .. .. ..$ : chr &quot;income&quot;
##   .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;income&quot;
##   .. ..- attr(*, &quot;order&quot;)= int 1
##   .. ..- attr(*, &quot;intercept&quot;)= int 1
##   .. ..- attr(*, &quot;response&quot;)= int 1
##   .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; 
##   .. ..- attr(*, &quot;predvars&quot;)= language list(prestige, income)
##   .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot;
##   .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;prestige&quot; &quot;income&quot;
##  $ model        :&#39;data.frame&#39;:   102 obs. of  2 variables:
##   ..$ prestige: num [1:102] 68.8 69.1 63.4 56.8 73.5 77.6 72.6 78.1 73.1 68.8 ...
##   ..$ income  : int [1:102] 12351 25879 9271 8865 8403 11030 8258 14163 11377 11023 ...
##   ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39; length 3 prestige ~ income
##   .. .. ..- attr(*, &quot;variables&quot;)= language list(prestige, income)
##   .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1
##   .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. .. .. ..$ : chr [1:2] &quot;prestige&quot; &quot;income&quot;
##   .. .. .. .. ..$ : chr &quot;income&quot;
##   .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;income&quot;
##   .. .. ..- attr(*, &quot;order&quot;)= int 1
##   .. .. ..- attr(*, &quot;intercept&quot;)= int 1
##   .. .. ..- attr(*, &quot;response&quot;)= int 1
##   .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; 
##   .. .. ..- attr(*, &quot;predvars&quot;)= language list(prestige, income)
##   .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot;
##   .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;prestige&quot; &quot;income&quot;
##  - attr(*, &quot;class&quot;)= chr &quot;lm&quot;</code></pre>
<p>An alternative (easier) way to pull out the fitted values and the coefficients would be to use the functions <code>fitted()</code> and <code>coefficients()</code>. Also, we can calculate the standard errors of the coefficients by taking the square root of the diagonal of the variance-covariance matrix.</p>
<pre class="r"><code># str(summary(reg))
fit_vals &lt;- fitted(reg)
coefs &lt;-  coefficients(reg)
se &lt;- sqrt(diag(vcov(reg)))
reg_table &lt;- data.frame(coefs = coefs, se = se)
reg_table</code></pre>
<pre><code>##                    coefs           se
## (Intercept) 27.141176368 2.2677036186
## income       0.002896799 0.0002833245</code></pre>
<p>The package <code>broom</code> has some functions to pull out and transform to friendly <code>data.frames</code> the output of statistical tests (e.g. <code>t.test</code>, <code>lm</code>, etc.). <code>broom</code> has 3 main functions:</p>
<ol style="list-style-type: decimal">
<li><code>tidy</code>: Transforms into a ready-to-go <code>data.frame</code> the coefficients, SEs (and CIs if given), critical values, and p-values in statistical tests’ outputs</li>
<li><code>augment</code>: Add columns to the original data that was modeled. This includes predictions, estandard error of the predictions, residuals, and others.</li>
<li><code>glance</code>: Always return a one-row <code>data.frame</code> that is a summary of the model: e.g. R2, adjusted R2, etc.</li>
</ol>
<pre class="r"><code>tidy(reg)</code></pre>
<pre><code>##          term     estimate    std.error statistic      p.value
## 1 (Intercept) 27.141176368 2.2677036186  11.96857 5.135229e-21
## 2      income  0.002896799 0.0002833245  10.22432 3.192004e-17</code></pre>
<pre class="r"><code>new_Prestige &lt;- augment(reg)
head(new_Prestige)</code></pre>
<pre><code>##             .rownames prestige income   .fitted  .se.fit     .resid
## 1  gov.administrators     68.8  12351  62.91954 1.976947   5.880457
## 2    general.managers     69.1  25879 102.10744 5.537087 -33.007443
## 3         accountants     63.4   9271  53.99740 1.387056   9.402598
## 4 purchasing.officers     56.8   8865  52.82130 1.332650   3.978699
## 5            chemists     73.5   8403  51.48298 1.280534  22.017020
## 6          physicists     77.6  11030  59.09287 1.694313  18.507128
##         .hat   .sigma      .cooksd .std.resid
## 1 0.02673970 12.13586 0.0033393128  0.4930373
## 2 0.20976307 11.56339 1.2519142229 -3.0712589
## 3 0.01316298 12.11335 0.0040878547  0.7829037
## 4 0.01215062 12.14398 0.0006742724  0.3311150
## 5 0.01121886 11.94513 0.0190283833  1.8314356
## 6 0.01964054 12.00454 0.0239440342  1.5460715</code></pre>
<ul>
<li><code>.fitted</code>: the model predictions for all observations</li>
<li><code>.se.fit</code>: the estandard error of the predictions</li>
<li><code>.resid</code>: the residuals of the predictions (acual - predicted values)</li>
<li><code>.sigma</code> is the standard error of the prediction.</li>
</ul>
<p>The other values <code>.hat</code>, <code>.cooksd</code>, and <code>.std.resid</code> are used in regression diagnostics.</p>
<pre class="r"><code>glance(reg)</code></pre>
<pre><code>##   r.squared adj.r.squared    sigma statistic      p.value df    logLik
## 1 0.5110901      0.506201 12.08974  104.5367 3.192004e-17  2 -397.9422
##        AIC      BIC deviance df.residual
## 1 801.8844 809.7593 14616.17         100</code></pre>
<p>For example, we can use the new dataset we created using the <code>augment()</code> function (<code>new_Prestige</code>) to plot the values of <code>income</code> predicted by the model (with 95% CIs) v. the actual values of <code>income</code>.</p>
<p>Fitted values plot: Comparing the actual observations v. what the model would predict.</p>
<pre class="r"><code>ggplot(new_Prestige, aes(x = income)) +
  geom_point(aes(y = prestige)) +
  geom_line(aes(y = .fitted))</code></pre>
<p><img src="cov_cor_regression_files/figure-html/unnamed-chunk-19-1.png" title="" alt="" width="672" /></p>
<p>Plot of the residuals: should be randomly distributed around 0 (<span class="math inline">\(\epsilon = N(0,\sigma^2)\)</span>). We shouldn’t observe any clear pattern.</p>
<pre class="r"><code>ggplot(new_Prestige, aes(x = income, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)</code></pre>
<p><img src="cov_cor_regression_files/figure-html/unnamed-chunk-20-1.png" title="" alt="" width="672" /></p>
<p>Density plot of residuals: should be normally distributed (<span class="math inline">\(\epsilon = N(0,\sigma^2)\)</span>).</p>
<pre class="r"><code>ggplot(new_Prestige, aes(x = .resid)) + 
  geom_density() +
  geom_rug()</code></pre>
<p><img src="cov_cor_regression_files/figure-html/unnamed-chunk-21-1.png" title="" alt="" width="672" /></p>
<p>Find the expected prestige of a job with incomes of 1000, 2000, 4000, and 8000.</p>
<pre class="r"><code>incomes &lt;- c(1000, 2000, 4000, 8000)
coef(reg)[&#39;(Intercept)&#39;] + coef(reg)[&#39;income&#39;] * incomes</code></pre>
<pre><code>## [1] 30.03798 32.93477 38.72837 50.31557</code></pre>
<p>Use predict to calculate predicted values of prestige.</p>
<pre class="r"><code>predict(reg, newdata = data.frame(income = incomes))</code></pre>
<pre><code>##        1        2        3        4 
## 30.03798 32.93477 38.72837 50.31557</code></pre>
</div>

<hr>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
R code is licensed under a <a href="https://www.r-project.org/Licenses/BSD_2_clause">BSD 2-clause</a> license.

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
