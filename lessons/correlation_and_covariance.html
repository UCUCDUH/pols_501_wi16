<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Jeffrey Arnold" />

<meta name="date" content="2016-02-25" />

<title>Covariance and Correlation</title>

<script src="libs/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.1/css/cerulean.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.1/shim/respond.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="libs/highlight/textmate.css"
      type="text/css" />
<script src="libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">

<p>
<strong>POL S/CS&amp;SS 501, University of Washington, Winter 2016</strong>
</p>

$$
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\SE}{se}
\DeclareMathOperator{\SD}{sd}
\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\argmax}{argmax}
$$

<div id="header">
<h1 class="title">Covariance and Correlation</h1>
<h4 class="author"><em>Jeffrey Arnold</em></h4>
<h4 class="date"><em>February 25, 2016</em></h4>
</div>

<div id="TOC">
<ul>
<li><a href="#covariance">Covariance</a></li>
<li><a href="#correlation">Correlation</a></li>
<li><a href="#anscombe-quartet">Anscombe Quartet</a></li>
</ul>
</div>

<pre class="r"><code>library(&quot;dplyr&quot;)
library(&quot;tidyr&quot;)
library(&quot;broom&quot;) 
library(&quot;ggplot2&quot;)
library(&quot;uwpols501&quot;)</code></pre>
<div id="covariance" class="section level2">
<h2>Covariance</h2>
<p>The sample covariance of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is, <span class="math display">\[
\Cov(x, y) = \frac{1}{n - 1} \sum_i (x_i - \bar{x}) (y_i - \bar{y})
\]</span></p>
<p>There is also corresponding parameter for the population defined in terms of the expectation of random variables. The covariance of random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are, <span class="math display">\[
\Cov(X, Y) = (X - \E(X)) (Y - \E(Y))
\]</span></p>
<ul>
<li>The covariance of a variable with itself is its variance, <span class="math display">\[
  Cov(x, x) = \frac{1}{n - 1} \sum_i (x_i - \bar{x}) (x_i - \bar{x}) = Var(x)
  \]</span></li>
<li>Like variance, the covariance includes the term <span class="math inline">\(1 / (n - 1)\)</span>. This is because dividing by <span class="math inline">\(n - 1\)</span> provides an unbiased estimate of the population covariance.</li>
<li>The range of covariance is <span class="math inline">\((-\infty, +\infty)\)</span>.</li>
<li>Covarariance does not change when a constant is added to either (or both) variables, <span class="math display">\[
  \begin{aligned}[t]
  Cov(x + a, y) = \frac{1}{n - 1} \sum_i ((x_i + a) - \overline{(x + a)} - b) (y_i - \bar{y}) \\
  = Cov(x + a, y) = \frac{1}{n - 1} \sum_i ((x_i + a) - \bar{x} - a) (y_i - \bar{y}) \\
  = Cov(x + a, y) = \frac{1}{n - 1} \sum_i (x_i + \bar{x}) (y_i - \bar{y}) \\
  = Cov(x, y)
  \end{aligned}[t]  
  \]</span></li>
<li>Covariance does change when either (or both) variables is multiplied by a constant. This implies that the scale of the variables affects the covariance. <span class="math display">\[
  \begin{aligned}[t]
  Cov(a x, y) = \frac{1}{n - 1} \sum_i (a x_i - \overline{(a x)) (y_i - \bar{y}) \\
  = Cov(a x, y) = \frac{1}{n - 1} \sum_i (ax_i - a\bar{x}) (y_i - \bar{y}) \\
  = Cov(a x, y) = \frac{a}{n - 1} \sum_i (x_i + \bar{x}) (y_i - \bar{y})
  = a Cov(x, y)
  \end{aligned}[t]
  \]</span></li>
</ul>
</div>
<div id="correlation" class="section level2">
<h2>Correlation</h2>
<p>The sample covariance of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is the covariance divided by the <span class="math display">\[
\Cor(x, y) = \Cov(x, y) / (\sd(x) \sd(y)) 
\]</span></p>
<ul>
<li>The correlation of a variable with itself is equal to one, <span class="math display">\[
  Cor(x, x) = \Cov(x, x) / (\sd(x) \sd(x)) = \Var(x) / \Var(x) = 1
  \]</span></li>
<li>The range of covariance is <span class="math inline">\((-1, 1)\)</span>.</li>
<li>Correlation does not change when a constant is added to either (or both) variables, <span class="math display">\[
  \begin{aligned}[t]
  \Cor(x + a, y) = \frac{\Cov(x + a, y)}{\sd(x + a) \sd(y)} = \frac{\Cov(x, y) }{ \sd(x) \sd(y)} = \Cor(x, y)
  \end{aligned}[t]  
  \]</span></li>
<li>Unlike covariance, correlation does not change when either (or both) variables is multiplied by a constant. Thus, the correlation of two variables, is not affected by the scale of those variables. <span class="math display">\[
  \begin{aligned}[t]
  \Cor(ax, y) = \frac{\Cov(ax, y)}{\sd(ax) \sd(y)} = \frac{a \Cov(x, y) }{a \sd(x) \sd(y)} = \Cor(x, y)
  \end{aligned}[t]
  \]</span></li>
</ul>
<div id="example" class="section level3">
<h3>Example</h3>
<p>What is the relationship between the log effective number of parties and redistribution?</p>
<pre class="r"><code>data(&quot;iver&quot;, package = &quot;uwpols501&quot;)</code></pre>
<pre class="r"><code>iver_cov_table_1 &lt;- 
  iver %&gt;%
    mutate(ln_enp = log(enp),
           ln_enp_diff = ln_enp - mean(ln_enp),
           povred_diff = povred - mean(povred),
           povred_diff_ln_enp_diff = ln_enp_diff * povred_diff) %&gt;%
    select(cty, povred, ln_enp, povred_diff,ln_enp_diff, povred_diff_ln_enp_diff)
iver_cov_table_1 %&gt;%
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">cty</th>
<th align="right">povred</th>
<th align="right">ln_enp</th>
<th align="right">povred_diff</th>
<th align="right">ln_enp_diff</th>
<th align="right">povred_diff_ln_enp_diff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Australia</td>
<td align="right">42.16</td>
<td align="right">0.8671005</td>
<td align="right">-8.657857</td>
<td align="right">-0.3334327</td>
<td align="right">2.8868129</td>
</tr>
<tr class="even">
<td align="left">Belgium</td>
<td align="right">78.79</td>
<td align="right">1.9473377</td>
<td align="right">27.972143</td>
<td align="right">0.7468045</td>
<td align="right">20.8897219</td>
</tr>
<tr class="odd">
<td align="left">Canada</td>
<td align="right">29.90</td>
<td align="right">0.5247285</td>
<td align="right">-20.917857</td>
<td align="right">-0.6758047</td>
<td align="right">14.1363858</td>
</tr>
<tr class="even">
<td align="left">Denmark</td>
<td align="right">71.54</td>
<td align="right">1.6174061</td>
<td align="right">20.722143</td>
<td align="right">0.4168729</td>
<td align="right">8.6384992</td>
</tr>
<tr class="odd">
<td align="left">Finland</td>
<td align="right">69.08</td>
<td align="right">1.6370531</td>
<td align="right">18.262143</td>
<td align="right">0.4365199</td>
<td align="right">7.9717882</td>
</tr>
<tr class="even">
<td align="left">France</td>
<td align="right">57.91</td>
<td align="right">0.9858168</td>
<td align="right">7.092143</td>
<td align="right">-0.2147164</td>
<td align="right">-1.5227995</td>
</tr>
<tr class="odd">
<td align="left">Germany</td>
<td align="right">46.90</td>
<td align="right">1.1505720</td>
<td align="right">-3.917857</td>
<td align="right">-0.0499612</td>
<td align="right">0.1957408</td>
</tr>
<tr class="even">
<td align="left">Italy</td>
<td align="right">42.81</td>
<td align="right">1.4134230</td>
<td align="right">-8.007857</td>
<td align="right">0.2128898</td>
<td align="right">-1.7047913</td>
</tr>
<tr class="odd">
<td align="left">Netherlands</td>
<td align="right">66.93</td>
<td align="right">1.2499017</td>
<td align="right">16.112143</td>
<td align="right">0.0493685</td>
<td align="right">0.7954327</td>
</tr>
<tr class="even">
<td align="left">Norway</td>
<td align="right">67.17</td>
<td align="right">1.1281711</td>
<td align="right">16.352143</td>
<td align="right">-0.0723621</td>
<td align="right">-1.1832757</td>
</tr>
<tr class="odd">
<td align="left">Sweden</td>
<td align="right">64.48</td>
<td align="right">1.2208299</td>
<td align="right">13.662143</td>
<td align="right">0.0202967</td>
<td align="right">0.2772966</td>
</tr>
<tr class="even">
<td align="left">Switzerland</td>
<td align="right">13.02</td>
<td align="right">1.6601310</td>
<td align="right">-37.797857</td>
<td align="right">0.4595978</td>
<td align="right">-17.3718126</td>
</tr>
<tr class="odd">
<td align="left">United Kingdom</td>
<td align="right">48.66</td>
<td align="right">0.7371641</td>
<td align="right">-2.157857</td>
<td align="right">-0.4633691</td>
<td align="right">0.9998844</td>
</tr>
<tr class="even">
<td align="left">United States</td>
<td align="right">12.10</td>
<td align="right">0.6678294</td>
<td align="right">-38.717857</td>
<td align="right">-0.5327038</td>
<td align="right">20.6251511</td>
</tr>
<tr class="odd">
<td align="left">The covariance is</td>
<td align="right">the sum</td>
<td align="right">of the produ</td>
<td align="right">ct of the diff</td>
<td align="right">erences betwee</td>
<td align="right">n the variables and their means,</td>
</tr>
</tbody>
</table>
<pre class="r"><code>summarize(iver_cov_table_1, sum(povred_diff_ln_enp_diff) / (n() - 1))</code></pre>
<pre><code>## Source: local data frame [1 x 1]
## 
##   sum(povred_diff_ln_enp_diff)/(n() - 1)
##                                    (dbl)
## 1                               4.279541</code></pre>
<p>We can confirm this using the <code>cov</code> function</p>
<pre class="r"><code>cov(iver$povred, log(iver$enp))</code></pre>
<pre><code>## [1] 4.279541</code></pre>
<p>Note that the covariance does not depend on the order of the variables,</p>
<pre class="r"><code>cov(log(iver$enp), iver$povred)</code></pre>
<pre><code>## [1] 4.279541</code></pre>
<p>The correlation divides the covariance by the product of the standard deviations of each variable,</p>
<pre class="r"><code>cov(iver$povred, log(iver$enp)) / (sd(iver$povred) * sd(log(iver$enp)))</code></pre>
<pre><code>## [1] 0.480118</code></pre>
<p>This agrees with the correlation as produced by <code>cor</code>,</p>
<pre class="r"><code>cor(iver$povred, log(iver$enp))</code></pre>
<pre><code>## [1] 0.480118</code></pre>
</div>
</div>
<div id="anscombe-quartet" class="section level2">
<h2>Anscombe Quartet</h2>
<p>The Anscombe quartet is a data frame included in</p>
<pre class="r"><code>data(&quot;anscombe&quot;, package = &quot;datasets&quot;)</code></pre>
<pre class="r"><code>anscombe_df &lt;- 
  as_data_frame(anscombe) %&gt;%
    mutate(id = row_number()) %&gt;%
    gather(variable_, value, -id) %&gt;%
    separate(variable_, c(&quot;variable&quot;, &quot;dataset&quot;), sep = 1) %&gt;%
    spread(variable, value)</code></pre>
<p>What are the means, standard deviations, and correlations of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> in each dataset,</p>
<pre class="r"><code>anscombe_df %&gt;%
  group_by(dataset) %&gt;%
  summarize(mean_x = mean(x),
            mean_y = mean(y),
            sd_x = sd(x),
            sd_y = sd(y),
            cor_xy = cor(x, y),
            cov_xy = cov(x, y))</code></pre>
<pre><code>## Source: local data frame [4 x 7]
## 
##   dataset mean_x   mean_y     sd_x     sd_y    cor_xy cov_xy
##     (chr)  (dbl)    (dbl)    (dbl)    (dbl)     (dbl)  (dbl)
## 1       1      9 7.500909 3.316625 2.031568 0.8164205  5.501
## 2       2      9 7.500909 3.316625 2.031657 0.8162365  5.500
## 3       3      9 7.500000 3.316625 2.030424 0.8162867  5.497
## 4       4      9 7.500909 3.316625 2.030579 0.8165214  5.499</code></pre>
<p>These datasets have the same means for <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, and approximately the same standard deviations of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, and the approximately same correlation and covariance between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. If we run linear regression on each of these, they have the same intercepts and slopes.</p>
<pre class="r"><code>anscombe_df %&gt;%
  group_by(dataset) %&gt;%
  do(tidy(lm(y ~ x, data = .))) %&gt;%
  select(term, estimate) %&gt;%
  spread(term, estimate)</code></pre>
<pre><code>## Source: local data frame [4 x 3]
## Groups: dataset [4]
## 
##   dataset (Intercept)         x
##     (chr)       (dbl)     (dbl)
## 1       1    3.000091 0.5000909
## 2       2    3.000909 0.5000000
## 3       3    3.002455 0.4997273
## 4       4    3.001727 0.4999091</code></pre>
<p>However, if we plot these datasets, although they have the same linear relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, they look very different.</p>
<pre class="r"><code>ggplot(anscombe_df, aes(x = x, y = y)) + 
  geom_point() +
  geom_smooth(method = &quot;lm&quot;, se = FALSE) +
  facet_wrap(~dataset)</code></pre>
<p><img src="correlation_and_covariance_files/figure-html/unnamed-chunk-13-1.png" title="" alt="" width="672" /></p>
<p>Note that correlation and covariance only measure the strength and direction of the linear relationship between two variables. It does not say anything about the slope of that linear relationship. Nor does it capture non-linear relationships between variables. The following figure illustrates these points:</p>
<p><img src="images/Correlation_examples2.svg" alt="Several sets of (x, y) points, with the Pearson correlation coefficient of x and y for each set" /></p>
<p>By <a href="//commons.wikimedia.org/w/index.php?title=User:DenisBoigelot&amp;action=edit&amp;redlink=1" class="new" title="User:DenisBoigelot (page does not exist)">DenisBoigelot</a>, original uploader was <a href="//en.wikipedia.org/wiki/User:Imagecreator" class="extiw" title="en:User:Imagecreator">Imagecreator</a> - <span class="int-own-work" lang="en">Own work</span>, original uploader was <a href="//en.wikipedia.org/wiki/User:Imagecreator" class="extiw" title="en:User:Imagecreator">Imagecreator</a>, <a href="http://creativecommons.org/publicdomain/zero/1.0/deed.en" title="Creative Commons Zero, Public Domain Dedication">CC0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=15165296" class="uri">https://commons.wikimedia.org/w/index.php?curid=15165296</a></p>
</div>

<hr>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
R code is licensed under a <a href="https://www.r-project.org/Licenses/BSD_2_clause">BSD 2-clause</a> license.

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
